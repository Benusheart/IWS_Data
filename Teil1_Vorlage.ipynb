{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Übung\n",
    "### Ziel: Einführung in die gängigsten Bewertungsmetriken und erste Hands-On Erfahrungen sammeln\n",
    "### Datensatz: Breast Cancer-Datensatz - aufbereitet und bereitgestellt von SciKit-Learn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Importiere folgende Packages:\n",
    "- pandas "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier importieren"
   ]
  },
  {
   "source": [
    "Lade den Datensatz"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          18.08         21.84          117.40     1024.0          0.07371   \n",
       "1          15.75         19.22          107.10      758.6          0.12430   \n",
       "2          10.05         17.53           64.41      310.8          0.10070   \n",
       "3          13.17         18.66           85.98      534.6          0.11580   \n",
       "4          10.88         15.62           70.41      358.9          0.10070   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "183        10.48         19.86           66.72      337.7          0.10700   \n",
       "184        18.61         20.25          122.10     1094.0          0.09440   \n",
       "185        14.95         18.77           97.84      689.5          0.08138   \n",
       "186        18.22         18.70          120.30     1033.0          0.11480   \n",
       "187        21.71         17.25          140.90     1546.0          0.09384   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.08642         0.11030              0.05778         0.1770   \n",
       "1             0.23640         0.29140              0.12420         0.2375   \n",
       "2             0.07326         0.02511              0.01775         0.1890   \n",
       "3             0.12310         0.12260              0.07340         0.2128   \n",
       "4             0.10690         0.05115              0.01571         0.1861   \n",
       "..                ...             ...                  ...            ...   \n",
       "183           0.05971         0.04831              0.03070         0.1737   \n",
       "184           0.10660         0.14900              0.07731         0.1697   \n",
       "185           0.11670         0.09050              0.03562         0.1744   \n",
       "186           0.14850         0.17720              0.10600         0.2092   \n",
       "187           0.08562         0.11680              0.08465         0.1717   \n",
       "\n",
       "     mean fractal dimension  ...  worst area  worst smoothness  \\\n",
       "0                   0.05340  ...      1228.0           0.08822   \n",
       "1                   0.07603  ...       915.3           0.15500   \n",
       "2                   0.06331  ...       384.0           0.14020   \n",
       "3                   0.06777  ...       759.4           0.17860   \n",
       "4                   0.06837  ...       433.1           0.13320   \n",
       "..                      ...  ...         ...               ...   \n",
       "183                 0.06440  ...       402.8           0.15150   \n",
       "184                 0.05699  ...      1403.0           0.13380   \n",
       "185                 0.06493  ...       809.7           0.09970   \n",
       "186                 0.06310  ...      1321.0           0.12800   \n",
       "187                 0.05054  ...      3143.0           0.13630   \n",
       "\n",
       "     worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0               0.1963           0.2535               0.09181          0.2369   \n",
       "1               0.5046           0.6872               0.21350          0.4245   \n",
       "2               0.1402           0.1055               0.06499          0.2894   \n",
       "3               0.4166           0.5006               0.20880          0.3900   \n",
       "4               0.3898           0.3365               0.07966          0.2581   \n",
       "..                 ...              ...                   ...             ...   \n",
       "183             0.1026           0.1181               0.06736          0.2883   \n",
       "184             0.2117           0.3446               0.14900          0.2341   \n",
       "185             0.2521           0.2500               0.08405          0.2852   \n",
       "186             0.2297           0.2623               0.13250          0.3021   \n",
       "187             0.1628           0.2861               0.18200          0.2510   \n",
       "\n",
       "     worst fractal dimension  Target_test  Prediction_Tree  Prediction_LogReg  \n",
       "0                    0.06558            0                0                  0  \n",
       "1                    0.10500            0                0                  0  \n",
       "2                    0.07664            1                1                  1  \n",
       "3                    0.11790            0                0                  0  \n",
       "4                    0.10800            1                1                  1  \n",
       "..                       ...          ...              ...                ...  \n",
       "183                  0.07748            1                1                  1  \n",
       "184                  0.07421            0                0                  0  \n",
       "185                  0.09218            1                1                  1  \n",
       "186                  0.07987            0                0                  0  \n",
       "187                  0.06494            0                0                  0  \n",
       "\n",
       "[188 rows x 33 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>...</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n      <th>Target_test</th>\n      <th>Prediction_Tree</th>\n      <th>Prediction_LogReg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>18.08</td>\n      <td>21.84</td>\n      <td>117.40</td>\n      <td>1024.0</td>\n      <td>0.07371</td>\n      <td>0.08642</td>\n      <td>0.11030</td>\n      <td>0.05778</td>\n      <td>0.1770</td>\n      <td>0.05340</td>\n      <td>...</td>\n      <td>1228.0</td>\n      <td>0.08822</td>\n      <td>0.1963</td>\n      <td>0.2535</td>\n      <td>0.09181</td>\n      <td>0.2369</td>\n      <td>0.06558</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>15.75</td>\n      <td>19.22</td>\n      <td>107.10</td>\n      <td>758.6</td>\n      <td>0.12430</td>\n      <td>0.23640</td>\n      <td>0.29140</td>\n      <td>0.12420</td>\n      <td>0.2375</td>\n      <td>0.07603</td>\n      <td>...</td>\n      <td>915.3</td>\n      <td>0.15500</td>\n      <td>0.5046</td>\n      <td>0.6872</td>\n      <td>0.21350</td>\n      <td>0.4245</td>\n      <td>0.10500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>10.05</td>\n      <td>17.53</td>\n      <td>64.41</td>\n      <td>310.8</td>\n      <td>0.10070</td>\n      <td>0.07326</td>\n      <td>0.02511</td>\n      <td>0.01775</td>\n      <td>0.1890</td>\n      <td>0.06331</td>\n      <td>...</td>\n      <td>384.0</td>\n      <td>0.14020</td>\n      <td>0.1402</td>\n      <td>0.1055</td>\n      <td>0.06499</td>\n      <td>0.2894</td>\n      <td>0.07664</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>13.17</td>\n      <td>18.66</td>\n      <td>85.98</td>\n      <td>534.6</td>\n      <td>0.11580</td>\n      <td>0.12310</td>\n      <td>0.12260</td>\n      <td>0.07340</td>\n      <td>0.2128</td>\n      <td>0.06777</td>\n      <td>...</td>\n      <td>759.4</td>\n      <td>0.17860</td>\n      <td>0.4166</td>\n      <td>0.5006</td>\n      <td>0.20880</td>\n      <td>0.3900</td>\n      <td>0.11790</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>10.88</td>\n      <td>15.62</td>\n      <td>70.41</td>\n      <td>358.9</td>\n      <td>0.10070</td>\n      <td>0.10690</td>\n      <td>0.05115</td>\n      <td>0.01571</td>\n      <td>0.1861</td>\n      <td>0.06837</td>\n      <td>...</td>\n      <td>433.1</td>\n      <td>0.13320</td>\n      <td>0.3898</td>\n      <td>0.3365</td>\n      <td>0.07966</td>\n      <td>0.2581</td>\n      <td>0.10800</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>183</td>\n      <td>10.48</td>\n      <td>19.86</td>\n      <td>66.72</td>\n      <td>337.7</td>\n      <td>0.10700</td>\n      <td>0.05971</td>\n      <td>0.04831</td>\n      <td>0.03070</td>\n      <td>0.1737</td>\n      <td>0.06440</td>\n      <td>...</td>\n      <td>402.8</td>\n      <td>0.15150</td>\n      <td>0.1026</td>\n      <td>0.1181</td>\n      <td>0.06736</td>\n      <td>0.2883</td>\n      <td>0.07748</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>184</td>\n      <td>18.61</td>\n      <td>20.25</td>\n      <td>122.10</td>\n      <td>1094.0</td>\n      <td>0.09440</td>\n      <td>0.10660</td>\n      <td>0.14900</td>\n      <td>0.07731</td>\n      <td>0.1697</td>\n      <td>0.05699</td>\n      <td>...</td>\n      <td>1403.0</td>\n      <td>0.13380</td>\n      <td>0.2117</td>\n      <td>0.3446</td>\n      <td>0.14900</td>\n      <td>0.2341</td>\n      <td>0.07421</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>185</td>\n      <td>14.95</td>\n      <td>18.77</td>\n      <td>97.84</td>\n      <td>689.5</td>\n      <td>0.08138</td>\n      <td>0.11670</td>\n      <td>0.09050</td>\n      <td>0.03562</td>\n      <td>0.1744</td>\n      <td>0.06493</td>\n      <td>...</td>\n      <td>809.7</td>\n      <td>0.09970</td>\n      <td>0.2521</td>\n      <td>0.2500</td>\n      <td>0.08405</td>\n      <td>0.2852</td>\n      <td>0.09218</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>186</td>\n      <td>18.22</td>\n      <td>18.70</td>\n      <td>120.30</td>\n      <td>1033.0</td>\n      <td>0.11480</td>\n      <td>0.14850</td>\n      <td>0.17720</td>\n      <td>0.10600</td>\n      <td>0.2092</td>\n      <td>0.06310</td>\n      <td>...</td>\n      <td>1321.0</td>\n      <td>0.12800</td>\n      <td>0.2297</td>\n      <td>0.2623</td>\n      <td>0.13250</td>\n      <td>0.3021</td>\n      <td>0.07987</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>187</td>\n      <td>21.71</td>\n      <td>17.25</td>\n      <td>140.90</td>\n      <td>1546.0</td>\n      <td>0.09384</td>\n      <td>0.08562</td>\n      <td>0.11680</td>\n      <td>0.08465</td>\n      <td>0.1717</td>\n      <td>0.05054</td>\n      <td>...</td>\n      <td>3143.0</td>\n      <td>0.13630</td>\n      <td>0.1628</td>\n      <td>0.2861</td>\n      <td>0.18200</td>\n      <td>0.2510</td>\n      <td>0.06494</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>188 rows × 33 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Hier Datensatz laden"
   ]
  },
  {
   "source": [
    "Wichtig: Der Datensatz ist schon aufbereitet und muss nicht mehr in Trainings- und Testdaten getrennt werden. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gebe Datensatz aus"
   ]
  },
  {
   "source": [
    "### Infos über den Datensatz\n",
    "1. 596 Instanzen\n",
    "2. Keine MissingValues\n",
    "3. 2 Klassen\n",
    "4. Target(0)=Maligne, Target(1)=Benigne\n",
    "5. Es gibt 30 Merkmale"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Bewertungsmetriken\n",
    "1. Accuracy\n",
    "2. Confusion Matrix\n",
    "3. ROC\n",
    "4. Log Loss\n",
    "5. Kohens Kappa"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1. Accuracy\n",
    "Übung: Verwende die Funktion accuracy_score().\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Accuracy von Modell1 berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Accuracy von Modell2 berechnen"
   ]
  },
  {
   "source": [
    "### 2. Confusion Matrix\n",
    "Übung: Verwende die Funktion confusion_matrix().\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ConfusionMatrix von Modell1 berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ConfusionMatrix von Modell2 berechnen"
   ]
  },
  {
   "source": [
    "### 3. ROC\n",
    "Übung: Verwende die Funktion roc_auc_score()\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ROC von Modell1 berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ROC von Modell2 berechnen"
   ]
  },
  {
   "source": [
    "#### 4. Log Loss\n",
    "- Ist im Prinzip eine Verlust-Funktion (LossFunction)\n",
    "- Sie sagt aus, wie gut die vorhersagten Wahrscheinlichkeiten einer Klasse einer Instanz ist. Zum Beispiel wissen wir die Klasse einer Instanz und haben die Wahrscheinlichkeit (Wahrscheinlichkeit, ob die Instanz zu der Klasse gehört) berechnet. \n",
    "- Wertebereich zwischen 0 bis ∞\n",
    "- Es gilt den Verlust minimal zu halten\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Übung: Verwende die Funktion log_loss().\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier LogLoss von Modell1 berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier LogLoss von Modell2 berechnen"
   ]
  }
 ]
}